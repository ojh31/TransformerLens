{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56161d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_250/572068249.py:21: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_250/572068249.py:22: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install git+https://github.com/neelnanda-io/TransformerLens.git``\n",
    "    %pip install circuitsvis\n",
    "    \n",
    "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
    "    # # Install another version of node that makes PySvelte work way faster\n",
    "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
    "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9f5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "from typing import List, Union, Optional\n",
    "from jaxtyping import Float, Int\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "# import circuitsvis as cv\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "from transformer_lens.utils import expand_alibi_on_query_dim\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e62f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"smallcloudai/Refact-1_6B-fim\"\n",
    "kwargs = dict(\n",
    "    trust_remote_code = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030c22b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTRefactForCausalLM(\n",
       "  (transformer): GPTRefactModel(\n",
       "    (wte): Embedding(49216, 2048)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x GPTRefactBlock(\n",
       "        (ln_1): LayerNormNoBias()\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (kv): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (c_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (ln_2): LayerNormNoBias()\n",
       "        (mlp): MLP(\n",
       "          (gate_up_proj): Linear(in_features=2048, out_features=11264, bias=False)\n",
       "          (c_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNormNoBias()\n",
       "  (lm_head): Linear(in_features=2048, out_features=49216, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load hf model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, **kwargs)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7ac1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model smallcloudai/Refact-1_6B-fim into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-31): 32 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable folding norms and folding biases so that intermediate value\n",
    "# in between transformer blocks can be compared\n",
    "tl_model = HookedTransformer.from_pretrained(\n",
    "    checkpoint,fold_ln=False, fold_value_biases=False, center_writing_weights=False,\n",
    "    **kwargs\n",
    ")\n",
    "tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3a3920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-31): 32 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1490c1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg logits difference: 1.0305025170964655e-06\n",
      "max logits difference: 186.43516540527344\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "TransformerLens lets you load in 50+ different open source language models,\n",
    "and exposes the internal activations of the model to you. You can cache\n",
    "any internal activation in the model, and add in functions to edit, remove\n",
    "or replace these activations as the model runs.\n",
    "'''\n",
    "# text = '''\n",
    "# <fim_prefix>def print_hello_world():\\n    \"\"\"<fim_suffix>\\n    print(\"Hello world!\")<fim_middle>\n",
    "# '''\n",
    "input_ids = tokenizer(text, return_tensors='pt')['input_ids']\n",
    "gt_logits = model(input_ids)['logits'] # ground truth logits from hf\n",
    "my_logits = tl_model(input_ids)\n",
    "centered_gt_logits = gt_logits - gt_logits.mean(-1, keepdim=True)\n",
    "mean_diff = (my_logits.cpu() - centered_gt_logits).mean()\n",
    "print(\"avg logits difference:\", mean_diff.item())\n",
    "max_diff = (my_logits.cpu() - centered_gt_logits).abs().max()\n",
    "print(\"max logits difference:\", max_diff.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e79eae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 88.1476,  43.4963,  54.2380, 202.8922,  50.5023,  83.2911, 172.1105,\n",
       "         182.6012, 101.0682, 108.3022, 192.1833, 194.4684, 125.4032, 188.9075,\n",
       "         144.4984, 165.8812, 107.8797, 188.0646, 132.9209,  40.5342, 175.5600,\n",
       "         174.1493, 236.4378, 176.7165, 167.8973,  54.8836, 158.3458, 153.1051,\n",
       "         199.3370,  49.3762, 212.5600,   7.0188, 184.3855, 175.7485,  71.8115,\n",
       "         179.1002, 183.5407,  98.9577, 110.6314, 204.5904, 140.7579,   9.6597,\n",
       "          81.8662, 163.4524, 215.9029, 137.6844, 194.3499,  33.3209, 206.1470,\n",
       "         153.4101, 127.5614, 190.0242, 189.7457, 241.1254, 191.4674, 208.0392,\n",
       "          19.7249,  52.7732, 162.7362,  37.2505, 167.2514]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_logits.max(dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb979ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 88.1476,  43.4963,  54.2380, 202.8922,  50.5023,  83.1182, 177.7963,\n",
       "         190.5575,  99.7517, 112.9961, 195.2906, 196.8482, 152.2427, 183.8413,\n",
       "         161.7404, 169.6966, 167.4622, 188.2148, 142.5233, 102.1532, 176.6607,\n",
       "         175.7684, 236.2870, 163.0893, 175.3592,  73.3941, 151.9742, 156.6560,\n",
       "         197.0582,  49.4439, 210.6001,   8.2312, 180.7817, 182.7687,  59.5721,\n",
       "         174.9992, 180.0233,  74.3021, 137.8261, 202.9162, 106.0415,  14.3899,\n",
       "          88.9807, 168.6275, 215.4047, 145.2605, 193.9221,  48.5591, 203.5147,\n",
       "         138.9817, 140.6528, 187.7079, 184.0011, 241.2458, 191.1526, 207.4595,\n",
       "          21.4716,  60.7495, 167.9026,  37.6301, 168.2901]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_logits.max(dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c31abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max embed diff 0.0\n"
     ]
    }
   ],
   "source": [
    "gt_wte = model.transformer.wte(input_ids).cpu()\n",
    "my_wte = tl_model.embed(input_ids).cpu()\n",
    "print(\"max embed diff\", (gt_wte - my_wte).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48806097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Matching hf and T-Lens residual stream in between transformer blocks *****\n",
      "layer 0 is close enough\n",
      "layer 1 \t not close, max difference: 0.48\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 124459 / 124928 (99.6%)\n",
      "Greatest absolute difference: 0.4802551567554474 at index (0, 12, 616) (up to 0.0001 allowed)\n",
      "Greatest relative difference: 56311.15234375 at index (0, 37, 1323) (up to 1e-05 allowed)\n"
     ]
    }
   ],
   "source": [
    "gt_cache = model(input_ids, output_hidden_states=True)['hidden_states']\n",
    "_, my_cache = tl_model.run_with_cache(input_ids)\n",
    "atol = 1e-4\n",
    "rtol = 1e-5\n",
    "print(\"*\"*5, \"Matching hf and T-Lens residual stream in between transformer blocks\", \"*\"*5)\n",
    "for i in range(tl_model.cfg.n_layers):\n",
    "    try:\n",
    "        torch.testing.assert_close(my_cache['resid_pre',i], gt_cache[i].cuda(), atol=atol, rtol=rtol)\n",
    "        print(f\"layer {i} is close enough\")\n",
    "    except AssertionError as e:\n",
    "        max_diff = (my_cache['resid_pre',i] - gt_cache[i].cuda()).abs().max()\n",
    "        print(f\"layer {i} \\t not close, max difference: {max_diff:.2f}\")\n",
    "        print(e)\n",
    "        break\n",
    "else: \n",
    "    print(f\"All layers match to atol={atol}, rtol={rtol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbd85d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max embed resid_pre diff 0.0\n"
     ]
    }
   ],
   "source": [
    "my_resid_pre_0 = my_cache[\"resid_pre\", 0].cpu()\n",
    "my_embed = tl_model.embed(input_ids).cpu()\n",
    "print(\"max embed resid_pre diff\", (my_embed - my_resid_pre_0).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe8a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_slopes(attn_heads: int, dev: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    ## Get head-specific slope $m$ for each head\n",
    "    * `n_heads` is the number of heads in the attention layer $n$\n",
    "    The slope for first head is\n",
    "    $$\\frac{1}{2^{\\frac{8}{n}}} = 2^{-\\frac{8}{n}}$$\n",
    "    The slopes for the rest of the heads are in a geometric series with a ratio same as above.\n",
    "    For instance when the number of heads is $8$ the slopes are\n",
    "    $$\\frac{1}{2^1}, \\frac{1}{2^2}, \\dots, \\frac{1}{2^8}$$\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the closest power of 2 to `n_heads`.\n",
    "    # If `n_heads` is not a power of 2, then we first calculate slopes to the closest (smaller) power of 2,\n",
    "    # and then add the remaining slopes.\n",
    "    n = 2 ** math.floor(math.log(attn_heads, 2))\n",
    "    # $2^{-\\frac{8}{n}}$\n",
    "    m_0 = 2.0 ** (-8.0 / n)\n",
    "    # $2^{-1\\frac{8}{n}}, 2^{-2 \\frac{8}{n}}, 2^{-3 \\frac{8}{n}}, \\dots$\n",
    "    m = torch.pow(m_0, torch.arange(1, 1 + n, device=dev))\n",
    "\n",
    "    # If `n_heads` is not a power of 2, then we add the remaining slopes.\n",
    "    # We calculate the remaining slopes for $n * 2$ (avoiding slopes added previously).\n",
    "    # And pick the slopes upto `n_heads`.\n",
    "    if n < attn_heads:\n",
    "        # $2^{-\\frac{8}{2n}}$\n",
    "        m_hat_0 = 2.0 ** (-4.0 / n)\n",
    "        # $2^{-1\\frac{8}{2n}}, 2^{-3 \\frac{8}{2n}}, 2^{-5 \\frac{8}{2n}}, \\dots$\n",
    "        # Note that we take steps by $2$ to avoid slopes added previously.\n",
    "        m_hat = torch.pow(m_hat_0, torch.arange(1, 1 + 2 * (attn_heads - n), 2, device=dev))\n",
    "        # Concatenate the slopes with the remaining slopes.\n",
    "        m = torch.cat([m, m_hat])\n",
    "    return m\n",
    "\n",
    "\n",
    "def get_alibi_biases(\n",
    "        B: int,\n",
    "        T: int,\n",
    "        attn_heads: int,\n",
    "        dev: torch.device,\n",
    "        dtype: torch.dtype) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    ## Calculate the attention biases matrix\n",
    "    * `n_heads` is the number of heads in the attention layer\n",
    "    * `mask` is the attention mask of shape `[seq_len_q, seq_len_k]`\n",
    "    This returns a matrix of shape `[seq_len_q, seq_len_k, n_heads, ]` with ALiBi attention biases.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get slopes $m$ for each head\n",
    "    mask = torch.ones((T, T), device=dev, dtype=torch.bool)\n",
    "\n",
    "    m = _get_slopes(attn_heads, dev).to(dtype)\n",
    "\n",
    "    # Calculate distances $[0, 1, \\dots, N]$\n",
    "    # Here we calculate the distances using the mask.\n",
    "    #\n",
    "    # Since it's causal mask we can just use $[0, 1, \\dots, N]$ too.\n",
    "    # `distance = torch.arange(mask.shape[1], dtype=torch.long, device=mask.device)[None, :]`\n",
    "    distance = mask.cumsum(dim=-1).to(dtype)\n",
    "\n",
    "    # Multiply them pair-wise to get the AliBi bias matrix\n",
    "    biases = distance[:, :, None] * m[None, None, :]\n",
    "    biases = biases.permute(2, 0, 1)[None, :, :T, :T]\n",
    "    return biases.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa04126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 61, 61])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length_with_past = query_length = input_ids.shape[1]\n",
    "alibi_dtype = torch.float32 if model.transformer.attention_bias_in_fp32 else model.transformer.wte.weight.dtype\n",
    "gt_alibi = get_alibi_biases(\n",
    "    my_resid_pre_0.shape[0], seq_length_with_past,\n",
    "    model.transformer.num_heads, \"cpu\", alibi_dtype\n",
    ")[:, :, -query_length:, :]\n",
    "gt_alibi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a3553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ln1 = tl_model.blocks[0].ln1(my_resid_pre_0.cuda()).cpu()\n",
    "gt_ln1 = model.transformer.h[0].ln_1(my_resid_pre_0)\n",
    "torch.testing.assert_close(my_ln1, gt_ln1, atol=1e-4, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741f01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max attn_out diff 0.44155019521713257\n"
     ]
    }
   ],
   "source": [
    "my_attn_out = my_cache[\"attn_out\", 0].cpu()\n",
    "gt_attn_out = model.transformer.h[0].attn(\n",
    "    model.transformer.h[0].ln_1(my_resid_pre_0),\n",
    "    alibi=gt_alibi,\n",
    ")[0]\n",
    "print(\"max attn_out diff\", (my_attn_out - gt_attn_out).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5590f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tl_model.cfg.positional_embedding_type == \"alibi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9301cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_q = my_cache[\"q\", 0].cpu()\n",
    "my_k = my_cache[\"k\", 0].cpu()\n",
    "my_v = my_cache[\"v\", 0].cpu()\n",
    "my_pattern = my_cache[\"pattern\", 0].cpu()\n",
    "my_z = my_cache[\"z\", 0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82c53f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 61, 61])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_attn = tl_model.blocks[0].attn\n",
    "my_raw_scores = (\n",
    "    einops.einsum(\n",
    "        my_q,\n",
    "        my_k,\n",
    "        \"batch query_pos head_index d_head, \\\n",
    "            batch key_pos head_index d_head \\\n",
    "            -> batch head_index query_pos key_pos\",\n",
    "    )\n",
    "    / tl_attn.attn_scale\n",
    ").cpu()\n",
    "my_raw_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c5a1329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 61, 61])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_alibi = tl_attn.compute_attention_linear_bias(\n",
    "    batch_size=my_raw_scores.size(0),\n",
    "    query_dim=my_raw_scores.size(-2),\n",
    "    key_dim=my_raw_scores.size(-1),\n",
    "    num_heads=tl_attn.cfg.n_heads,\n",
    "    device=my_raw_scores.device,\n",
    ").to(my_raw_scores.device)\n",
    "my_alibi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27ff9f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 61, 61]), torch.Size([1, 32, 61, 61]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_alibi.shape, gt_alibi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b6fc54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8409,  1.6818,  2.5227,  3.3636,  4.2045,  5.0454,  5.8863,  6.7272,\n",
       "         7.5681,  8.4090,  9.2499, 10.0908, 10.9317, 11.7725, 12.6134, 13.4543,\n",
       "        14.2952, 15.1361, 15.9770, 16.8179, 17.6588, 18.4997, 19.3406, 20.1815,\n",
       "        21.0224, 21.8633, 22.7042, 23.5451, 24.3860, 25.2269, 26.0678, 26.9087,\n",
       "        27.7496, 28.5905, 29.4314, 30.2723, 31.1132, 31.9541, 32.7950, 33.6359,\n",
       "        34.4768, 35.3176, 36.1585, 36.9994, 37.8403, 38.6812, 39.5221, 40.3630,\n",
       "        41.2039, 42.0448, 42.8857, 43.7266, 44.5675, 45.4084, 46.2493, 47.0902,\n",
       "        47.9311, 48.7720, 49.6129, 50.4538, 51.2947])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_alibi[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d9e4922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 61, 61])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_alibi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5280c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(my_alibi, gt_alibi, atol=1e-4, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3f89a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_attn = model.transformer.h[0].attn\n",
    "hidden_states = gt_ln1\n",
    "gt_query = hf_attn.q(hidden_states)\n",
    "gt_kv = hf_attn.kv(hidden_states)\n",
    "gt_key, gt_value = gt_kv.split(hf_attn.head_dim, dim=-1)\n",
    "gt_key = gt_key.transpose(-1, -2)\n",
    "gt_attn_out, gt_attn_probs = model.transformer.h[0].attn._attn(\n",
    "    gt_query, gt_key, gt_value, alibi=gt_alibi\n",
    ")\n",
    "gt_attn_probs = einops.rearrange(\n",
    "    gt_attn_probs, \"batch dest head src -> batch head dest src\"\n",
    ")  # rearrange to match T-Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "812f3023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 61, 32, 61])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = gt_query.dtype\n",
    "softmax_dtype = torch.float32 if hf_attn.attention_softmax_in_fp32 else dtype\n",
    "mask_value = hf_attn._get_mask_value(gt_query.device, softmax_dtype)\n",
    "upcast = dtype != softmax_dtype\n",
    "\n",
    "query_shape = gt_query.shape\n",
    "batch_size = query_shape[0]\n",
    "key_length = gt_key.size(-1)\n",
    "\n",
    "# (batch_size, query_length, num_heads, head_dim) x (batch_size, head_dim, key_length)\n",
    "# -> (batch_size, query_length, num_heads, key_length)\n",
    "query_length = query_shape[1]\n",
    "attn_shape = (batch_size, query_length, hf_attn.num_heads, key_length)\n",
    "attn_view = (batch_size, query_length * hf_attn.num_heads, key_length)\n",
    "# No copy needed for MQA 2, or when layer_past is provided.\n",
    "query = gt_query.reshape(batch_size, query_length * hf_attn.num_heads, hf_attn.head_dim)\n",
    "\n",
    "alibi = gt_alibi.transpose(2, 1).reshape(gt_alibi.shape[0], -1, gt_alibi.shape[-1])\n",
    "initial_dtype = query.dtype\n",
    "new_dtype = torch.float32 if hf_attn.attention_bias_in_fp32 else initial_dtype\n",
    "gt_attn_scores = alibi.baddbmm(\n",
    "    batch1=query.to(new_dtype),\n",
    "    batch2=gt_key.to(new_dtype),\n",
    "    beta=1,\n",
    "    alpha=hf_attn.scale_factor\n",
    ").view(attn_shape).to(initial_dtype)\n",
    "gt_attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c3ae891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1952, 61]),\n",
       " torch.Size([1, 1952, 64]),\n",
       " torch.Size([1, 64, 61]),\n",
       " (1, 61, 32, 61))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alibi.shape, query.shape, gt_key.shape, attn_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e76afed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 61, 61]), torch.Size([1, 32, 61, 61]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_attn_probs.shape, my_pattern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ca0f269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999403953552"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_attn_probs[0, 0, 0, :].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c7095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(gt_attn_probs[0, 0, 0, :].sum().item(), 1)\n",
    "assert np.isclose(my_pattern[0, 1, 7, :].sum().item(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8844cd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.3539e-23, 7.8172e-23, 1.6393e-22, 4.8567e-22, 1.3540e-21, 1.5993e-21,\n",
       "        6.2428e-21, 1.6799e-20, 2.7481e-20, 3.7070e-20, 2.2339e-19, 4.2720e-19,\n",
       "        5.9115e-19, 1.7237e-18, 4.1119e-18, 7.3680e-18, 3.9440e-17, 1.3497e-16,\n",
       "        9.0752e-17, 3.3818e-16, 1.0776e-15, 1.7558e-15, 3.1890e-15, 5.3143e-15,\n",
       "        2.1934e-14, 7.2182e-14, 5.8982e-14, 2.2290e-13, 7.8765e-13, 2.5831e-12,\n",
       "        4.8612e-12, 6.7880e-12, 1.6573e-11, 9.4055e-11, 5.1103e-11, 2.2763e-10,\n",
       "        3.8827e-10, 1.3076e-09, 4.0363e-09, 3.2982e-09, 2.2943e-08, 5.5779e-08,\n",
       "        4.3746e-08, 2.0308e-07, 4.3188e-07, 8.3493e-07, 1.2914e-06, 8.2610e-06,\n",
       "        1.0137e-05, 6.5543e-05, 2.9327e-05, 1.1949e-04, 3.9717e-04, 6.6797e-04,\n",
       "        1.1131e-03, 4.3888e-03, 1.5119e-02, 1.2354e-02, 5.0506e-02, 2.3336e-01,\n",
       "        6.8185e-01])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_attn_probs[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3842d8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6476e-23, 2.0203e-22, 4.4693e-22, 1.0005e-21, 2.4869e-21, 5.5021e-21,\n",
       "        1.3122e-20, 2.5021e-20, 6.5520e-20, 1.7095e-19, 3.3954e-19, 8.5492e-19,\n",
       "        2.0174e-18, 4.6534e-18, 1.0808e-17, 2.4423e-17, 4.7207e-17, 1.0740e-16,\n",
       "        3.1519e-16, 7.4592e-16, 1.7417e-15, 3.8459e-15, 8.8277e-15, 2.0522e-14,\n",
       "        4.6332e-14, 1.1667e-13, 2.6031e-13, 6.0290e-13, 1.4467e-12, 2.5912e-12,\n",
       "        7.6673e-12, 1.7205e-11, 3.8876e-11, 7.4844e-11, 2.3331e-10, 4.9860e-10,\n",
       "        1.1733e-09, 2.7485e-09, 6.5240e-09, 1.4556e-08, 2.7462e-08, 7.7435e-08,\n",
       "        1.8231e-07, 4.2686e-07, 9.3600e-07, 2.2583e-06, 5.1374e-06, 9.8879e-06,\n",
       "        2.8244e-05, 5.2156e-05, 1.5148e-04, 3.5829e-04, 8.4296e-04, 1.8490e-03,\n",
       "        4.2986e-03, 1.0294e-02, 2.4437e-02, 5.4524e-02, 1.2646e-01, 2.3410e-01,\n",
       "        5.4258e-01])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pattern[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb49e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_attn.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a288125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_attn._attn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971baa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_attn_scores[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(gt_attn_probs, my_pattern, atol=1e-4, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_attn_out.shape, my_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_model.blocks[0].attn.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_attn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loss = tl_model(input_ids, return_type='loss')\n",
    "print(\"T-Lens next token loss:\", my_loss.item())\n",
    "gt_outputs = model(input_ids, labels=input_ids)\n",
    "gt_loss = gt_outputs.loss\n",
    "print(\"HF next token loss:\", gt_loss.item())\n",
    "print(\"diff in loss (abs):\", (gt_loss-my_loss).abs().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0f24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6c928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
